{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK Test \n",
    "http://textminingonline.com/dive-into-nltk-part-i-getting-started-with-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Test Brown Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Fulton',\n",
       " 'County',\n",
       " 'Grand',\n",
       " 'Jury',\n",
       " 'said',\n",
       " 'Friday',\n",
       " 'an',\n",
       " 'investigation',\n",
       " 'of']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.words()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('Fulton', 'NP-TL'),\n",
       " ('County', 'NN-TL'),\n",
       " ('Grand', 'JJ-TL'),\n",
       " ('Jury', 'NN-TL'),\n",
       " ('said', 'VBD'),\n",
       " ('Friday', 'NR'),\n",
       " ('an', 'AT'),\n",
       " ('investigation', 'NN'),\n",
       " ('of', 'IN')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.tagged_words()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1161192"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '__weakref__',\n",
       " '_add',\n",
       " '_c2f',\n",
       " '_delimiter',\n",
       " '_encoding',\n",
       " '_f2c',\n",
       " '_file',\n",
       " '_fileids',\n",
       " '_get_root',\n",
       " '_init',\n",
       " '_map',\n",
       " '_para_block_reader',\n",
       " '_pattern',\n",
       " '_resolve',\n",
       " '_root',\n",
       " '_sent_tokenizer',\n",
       " '_sep',\n",
       " '_tagset',\n",
       " '_unload',\n",
       " '_word_tokenizer',\n",
       " 'abspath',\n",
       " 'abspaths',\n",
       " 'categories',\n",
       " 'citation',\n",
       " 'encoding',\n",
       " 'ensure_loaded',\n",
       " 'fileids',\n",
       " 'license',\n",
       " 'open',\n",
       " 'paras',\n",
       " 'raw',\n",
       " 'readme',\n",
       " 'root',\n",
       " 'sents',\n",
       " 'tagged_paras',\n",
       " 'tagged_sents',\n",
       " 'tagged_words',\n",
       " 'unicode_repr',\n",
       " 'words']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(brown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test NLTK Book Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_CONTEXT_RE',\n",
       " '_COPY_TOKENS',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '__weakref__',\n",
       " '_context',\n",
       " 'collocations',\n",
       " 'common_contexts',\n",
       " 'concordance',\n",
       " 'count',\n",
       " 'dispersion_plot',\n",
       " 'findall',\n",
       " 'generate',\n",
       " 'index',\n",
       " 'name',\n",
       " 'plot',\n",
       " 'readability',\n",
       " 'similar',\n",
       " 'tokens',\n",
       " 'unicode_repr',\n",
       " 'vocab']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260819"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sent Tokenize(sentence boundary detection, sentence segmentation), Word Tokenize and Pos Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine learning is the science of getting computers to act without being explicitly programmed.',\n",
       " 'In the past decade, machine learning has given us self-driving cars, practical speech recognition, effective web search, and a vastly improved understanding of the human genome.',\n",
       " 'Machine learning is so pervasive today that you probably use it dozens of times a day without knowing it.',\n",
       " 'Many researchers also think it is the best way to make progress towards human-level AI.',\n",
       " 'In this class, you will learn about the most effective machine learning techniques, and gain practice implementing them and getting them to work for yourself.',\n",
       " \"More importantly, you'll learn about not only the theoretical underpinnings of learning, but also gain the practical know-how needed to quickly and powerfully apply these techniques to new problems.\",\n",
       " \"Finally, you'll learn about some of Silicon Valley's best practices in innovation as it pertains to machine learning and AI.\"]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "text = \"Machine learning is the science of getting computers to act without being explicitly programmed. In the past decade, machine learning has given us self-driving cars, practical speech recognition, effective web search, and a vastly improved understanding of the human genome. Machine learning is so pervasive today that you probably use it dozens of times a day without knowing it. Many researchers also think it is the best way to make progress towards human-level AI. In this class, you will learn about the most effective machine learning techniques, and gain practice implementing them and getting them to work for yourself. More importantly, you'll learn about not only the theoretical underpinnings of learning, but also gain the practical know-how needed to quickly and powerfully apply these techniques to new problems. Finally, you'll learn about some of Silicon Valley's best practices in innovation as it pertains to machine learning and AI.\"\n",
    "\n",
    "sents = sent_tokenize(text)\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine',\n",
       " 'learning',\n",
       " 'is',\n",
       " 'the',\n",
       " 'science',\n",
       " 'of',\n",
       " 'getting',\n",
       " 'computers',\n",
       " 'to',\n",
       " 'act',\n",
       " 'without',\n",
       " 'being',\n",
       " 'explicitly',\n",
       " 'programmed',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'past',\n",
       " 'decade',\n",
       " ',',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'has',\n",
       " 'given',\n",
       " 'us',\n",
       " 'self-driving',\n",
       " 'cars',\n",
       " ',',\n",
       " 'practical',\n",
       " 'speech',\n",
       " 'recognition',\n",
       " ',',\n",
       " 'effective',\n",
       " 'web',\n",
       " 'search',\n",
       " ',',\n",
       " 'and',\n",
       " 'a',\n",
       " 'vastly',\n",
       " 'improved',\n",
       " 'understanding',\n",
       " 'of',\n",
       " 'the',\n",
       " 'human',\n",
       " 'genome',\n",
       " '.',\n",
       " 'Machine',\n",
       " 'learning',\n",
       " 'is',\n",
       " 'so',\n",
       " 'pervasive',\n",
       " 'today',\n",
       " 'that',\n",
       " 'you',\n",
       " 'probably',\n",
       " 'use',\n",
       " 'it',\n",
       " 'dozens',\n",
       " 'of',\n",
       " 'times',\n",
       " 'a',\n",
       " 'day',\n",
       " 'without',\n",
       " 'knowing',\n",
       " 'it',\n",
       " '.',\n",
       " 'Many',\n",
       " 'researchers',\n",
       " 'also',\n",
       " 'think',\n",
       " 'it',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'way',\n",
       " 'to',\n",
       " 'make',\n",
       " 'progress',\n",
       " 'towards',\n",
       " 'human-level',\n",
       " 'AI',\n",
       " '.',\n",
       " 'In',\n",
       " 'this',\n",
       " 'class',\n",
       " ',',\n",
       " 'you',\n",
       " 'will',\n",
       " 'learn',\n",
       " 'about',\n",
       " 'the',\n",
       " 'most',\n",
       " 'effective',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'techniques',\n",
       " ',',\n",
       " 'and',\n",
       " 'gain',\n",
       " 'practice',\n",
       " 'implementing',\n",
       " 'them',\n",
       " 'and',\n",
       " 'getting',\n",
       " 'them',\n",
       " 'to',\n",
       " 'work',\n",
       " 'for',\n",
       " 'yourself',\n",
       " '.',\n",
       " 'More',\n",
       " 'importantly',\n",
       " ',',\n",
       " 'you',\n",
       " \"'ll\",\n",
       " 'learn',\n",
       " 'about',\n",
       " 'not',\n",
       " 'only',\n",
       " 'the',\n",
       " 'theoretical',\n",
       " 'underpinnings',\n",
       " 'of',\n",
       " 'learning',\n",
       " ',',\n",
       " 'but',\n",
       " 'also',\n",
       " 'gain',\n",
       " 'the',\n",
       " 'practical',\n",
       " 'know-how',\n",
       " 'needed',\n",
       " 'to',\n",
       " 'quickly',\n",
       " 'and',\n",
       " 'powerfully',\n",
       " 'apply',\n",
       " 'these',\n",
       " 'techniques',\n",
       " 'to',\n",
       " 'new',\n",
       " 'problems',\n",
       " '.',\n",
       " 'Finally',\n",
       " ',',\n",
       " 'you',\n",
       " \"'ll\",\n",
       " 'learn',\n",
       " 'about',\n",
       " 'some',\n",
       " 'of',\n",
       " 'Silicon',\n",
       " 'Valley',\n",
       " \"'s\",\n",
       " 'best',\n",
       " 'practices',\n",
       " 'in',\n",
       " 'innovation',\n",
       " 'as',\n",
       " 'it',\n",
       " 'pertains',\n",
       " 'to',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'and',\n",
       " 'AI',\n",
       " '.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Machine', 'NN'),\n",
       " ('learning', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('science', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('getting', 'VBG'),\n",
       " ('computers', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('act', 'VB'),\n",
       " ('without', 'IN'),\n",
       " ('being', 'VBG'),\n",
       " ('explicitly', 'RB'),\n",
       " ('programmed', 'VBN'),\n",
       " ('.', '.'),\n",
       " ('In', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('past', 'JJ'),\n",
       " ('decade', 'NN'),\n",
       " (',', ','),\n",
       " ('machine', 'NN'),\n",
       " ('learning', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('given', 'VBN'),\n",
       " ('us', 'PRP'),\n",
       " ('self-driving', 'JJ'),\n",
       " ('cars', 'NNS'),\n",
       " (',', ','),\n",
       " ('practical', 'JJ'),\n",
       " ('speech', 'NN'),\n",
       " ('recognition', 'NN'),\n",
       " (',', ','),\n",
       " ('effective', 'JJ'),\n",
       " ('web', 'NN'),\n",
       " ('search', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('a', 'DT'),\n",
       " ('vastly', 'RB'),\n",
       " ('improved', 'VBN'),\n",
       " ('understanding', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('human', 'JJ'),\n",
       " ('genome', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Machine', 'NNP'),\n",
       " ('learning', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('so', 'RB'),\n",
       " ('pervasive', 'JJ'),\n",
       " ('today', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('probably', 'RB'),\n",
       " ('use', 'VBP'),\n",
       " ('it', 'PRP'),\n",
       " ('dozens', 'VBZ'),\n",
       " ('of', 'IN'),\n",
       " ('times', 'NNS'),\n",
       " ('a', 'DT'),\n",
       " ('day', 'NN'),\n",
       " ('without', 'IN'),\n",
       " ('knowing', 'VBG'),\n",
       " ('it', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('Many', 'JJ'),\n",
       " ('researchers', 'NNS'),\n",
       " ('also', 'RB'),\n",
       " ('think', 'VBP'),\n",
       " ('it', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('best', 'JJS'),\n",
       " ('way', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('make', 'VB'),\n",
       " ('progress', 'NN'),\n",
       " ('towards', 'IN'),\n",
       " ('human-level', 'NN'),\n",
       " ('AI', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('In', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('class', 'NN'),\n",
       " (',', ','),\n",
       " ('you', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('learn', 'VB'),\n",
       " ('about', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('most', 'RBS'),\n",
       " ('effective', 'JJ'),\n",
       " ('machine', 'NN'),\n",
       " ('learning', 'VBG'),\n",
       " ('techniques', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('gain', 'NN'),\n",
       " ('practice', 'NN'),\n",
       " ('implementing', 'VBG'),\n",
       " ('them', 'PRP'),\n",
       " ('and', 'CC'),\n",
       " ('getting', 'VBG'),\n",
       " ('them', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('work', 'VB'),\n",
       " ('for', 'IN'),\n",
       " ('yourself', 'PRP'),\n",
       " ('.', '.'),\n",
       " ('More', 'RBR'),\n",
       " ('importantly', 'RB'),\n",
       " (',', ','),\n",
       " ('you', 'PRP'),\n",
       " (\"'ll\", 'MD'),\n",
       " ('learn', 'VB'),\n",
       " ('about', 'IN'),\n",
       " ('not', 'RB'),\n",
       " ('only', 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('theoretical', 'JJ'),\n",
       " ('underpinnings', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('learning', 'NN'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('also', 'RB'),\n",
       " ('gain', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('practical', 'JJ'),\n",
       " ('know-how', 'NN'),\n",
       " ('needed', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('quickly', 'RB'),\n",
       " ('and', 'CC'),\n",
       " ('powerfully', 'RB'),\n",
       " ('apply', 'VB'),\n",
       " ('these', 'DT'),\n",
       " ('techniques', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('new', 'JJ'),\n",
       " ('problems', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Finally', 'RB'),\n",
       " (',', ','),\n",
       " ('you', 'PRP'),\n",
       " (\"'ll\", 'MD'),\n",
       " ('learn', 'VB'),\n",
       " ('about', 'IN'),\n",
       " ('some', 'DT'),\n",
       " ('of', 'IN'),\n",
       " ('Silicon', 'NNP'),\n",
       " ('Valley', 'NNP'),\n",
       " (\"'s\", 'POS'),\n",
       " ('best', 'JJS'),\n",
       " ('practices', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('innovation', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('pertains', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('machine', 'NN'),\n",
       " ('learning', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('AI', 'NNP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_tokens = pos_tag(tokens)\n",
    "tagged_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In linguistic morphology and information retrieval, stemming is the process for reducing inflected (or sometimes derived) words to their stem, base or root form—generally a written word form. The stem need not be identical to the morphological root of the word; it is usually sufficient that related words map to the same stem, even if this stem is not in itself a valid root. Algorithms for stemming have been studied in computer science since the 1960s. Many search engines treat words with the same stem as synonyms as a kind of query expansion, a process called conflation.\n",
    "\n",
    "Stemming programs are commonly referred to as stemming algorithms or stemmers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "from nltk.stem import SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['maximum',\n",
       " 'presum',\n",
       " 'multipli',\n",
       " 'provis',\n",
       " 'owe',\n",
       " 'ear',\n",
       " 'say',\n",
       " 'cri',\n",
       " 'string',\n",
       " 'meant',\n",
       " 'cement']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['maximum','presumably','multiply','provision','owed','ear','saying','crying','string','meant','cement']\n",
    "\n",
    "porter_words = []\n",
    "for word in words:\n",
    "    porter_words.append(porter_stemmer.stem(word))\n",
    "\n",
    "porter_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['maxim',\n",
       " 'presum',\n",
       " 'multiply',\n",
       " 'provid',\n",
       " 'ow',\n",
       " 'ear',\n",
       " 'say',\n",
       " 'cry',\n",
       " 'string',\n",
       " 'meant',\n",
       " 'cem']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lancaster_words = []\n",
    "for word in words:\n",
    "    lancaster_words.append(lancaster_stemmer.stem(word))\n",
    "\n",
    "lancaster_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['maximum',\n",
       " 'presum',\n",
       " 'multipli',\n",
       " 'provis',\n",
       " 'owe',\n",
       " 'ear',\n",
       " 'say',\n",
       " 'cri',\n",
       " 'string',\n",
       " 'meant',\n",
       " 'cement']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball_words = []\n",
    "for word in words:\n",
    "    snowball_words.append(snowball_stemmer.stem(word))\n",
    "\n",
    "snowball_words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatisation (or lemmatization) in linguistics, is the process of grouping together the different inflected forms of a word so they can be analysed as a single item.\n",
    "\n",
    "In computational linguistics, lemmatisation is the algorithmic process of determining the lemma for a given word. Since the process may involve complex tasks such as understanding context and determining the part of speech of a word in a sentence (requiring, for example, knowledge of the grammar of a language) it can be a hard task to implement a lemmatiser for a new language.\n",
    "\n",
    "In many languages, words appear in several inflected forms. For example, in English, the verb ‘to walk’ may appear as ‘walk’, ‘walked’, ‘walks’, ‘walking’. The base form, ‘walk’, that one might look up in a dictionary, is called the lemma for the word. The combination of the base form with the part of speech is often called the lexeme of the word.\n",
    "\n",
    "Lemmatisation is closely related to stemming. The difference is that a stemmer operates on a single word without knowledge of the context, and therefore cannot discriminate between words which have different meanings depending on part of speech. However, stemmers are typically easier to implement and run faster, and the reduced accuracy may not matter for some applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
